{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVR for approximation of the fundamental matrices of image pairs\n",
    "### to learn the ropes of the evaluation metric and establish our first (definitely bad) baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The general Task:\n",
    "\n",
    "- The datasets are large and a baseline model which is not a neural network is definitely going to have a hard time here. We came up with the idea of applying an SVM to solve for the fundamental matrices of the image pairs.\n",
    "- Due to the sheer size of the data (over 1.4 million pairings), the fact that for each pairing, a set of 2 images per pair (already resized by us to 150*150 px, resulting in 150x150 _px_ x3 _colors_ = 67500 features) and the fact that SVMs tend to become slower the larger the datasets become, we decided to only work with a small subsample of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import model\n",
    "import validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the list \"scenes\" tells the code, which scenes to load (see *list of all scenes* below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '../../data/train/' # directory of the training data\n",
    "\n",
    "# list of all scenes: [\"british_museum\", \"brandenburg_gate\", \"buckingham_palace\",\n",
    "#  \"colosseum_exterior\", \"grand_place_brussels\", \"lincoln_memorial_statue\",\n",
    "#  \"notre_dame_front_facade\", \"pantheon_exterior\", \"piazza_san_marco\",\n",
    "#  \"sacre_coeur\", \"sagrada_familia\", \"st_pauls_cathedral\", \"st_peters_square\",\n",
    "#  \"taj_mahal\", \"temple_nara_japan\", \"trevi_fountain\"]\n",
    "\n",
    "scenes=[\"brandenburg_gate\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the corresponding dataframes, containing either image pairs or processed 150x150 images with their image IDs are loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading category 1 of 1: brandenburg_gate\n",
      "loaded brandenburg_gate successfully\n"
     ]
    }
   ],
   "source": [
    "df, images = model.load_scenes(scenes, input_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test-Split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df[[\"image1_id\", \"image2_id\",\"pair\", \"building\"]]\n",
    "y= df[[\"fm1\",\"fm2\",\"fm3\",\"fm4\",\"fm5\",\"fm6\",\"fm7\",\"fm8\",\"fm9\"]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, train_size= 0.2, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset is _only_ n = 500 pairings, although even a scene with only 300 images contains pairing data for (300^2)/2= *61250* image pairs. each of which containing *67500* features. \n",
    "\n",
    "Without dimensionality reduction, this otherwise takes a LOT of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 250\n",
    "x_train_short = x_train[0:min(n,x_train.shape[0])]\n",
    "y_train_short = y_train[0:min(n,y_train.shape[0])]\n",
    "x_test_short = x_test[0:min(n*5,x_test.shape[0])]\n",
    "y_test_short = y_test[0:min(n*5,y_test.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Prediction is performed with 9 separately initialized LinearSVR models. these don't communicate with each other, as opposed to models capable of classifying/regressing for multiples targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting dataset of 250 training entries\n",
      "then predicting 1250 test entries\n",
      "------------------------------\n",
      "inflating 1500 entries with images\n",
      "training data:\n",
      "starting inflating 🐡\n",
      "done inflating 💥\n",
      "test data:\n",
      "starting inflating 🐡\n",
      "done inflating 💥\n",
      "------------------------------\n",
      "initialising models... 🤖\n",
      "------------------------------\n",
      "fitting model1 for fm1 📐\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toasters/Desktop/neuefische/capstone-project-image-matching-challenge/.venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting 🔮\n",
      "------------------------------\n",
      "fitting model2 for fm2 📐\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toasters/Desktop/neuefische/capstone-project-image-matching-challenge/.venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting 🔮\n",
      "------------------------------\n",
      "fitting model3 for fm3 📐\n",
      "predicting 🔮\n",
      "------------------------------\n",
      "fitting model4 for fm4 📐\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toasters/Desktop/neuefische/capstone-project-image-matching-challenge/.venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting 🔮\n",
      "------------------------------\n",
      "fitting model5 for fm5 📐\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toasters/Desktop/neuefische/capstone-project-image-matching-challenge/.venv/lib/python3.9/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting 🔮\n",
      "------------------------------\n",
      "fitting model6 for fm6 📐\n",
      "predicting 🔮\n",
      "------------------------------\n",
      "fitting model7 for fm7 📐\n",
      "predicting 🔮\n",
      "------------------------------\n",
      "fitting model8 for fm8 📐\n",
      "predicting 🔮\n",
      "------------------------------\n",
      "fitting model9 for fm9 📐\n",
      "predicting 🔮\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.fit_pred_9xLinSVR(x_train_short,x_test_short,y_train_short, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the imported evaluation metrics to properly work, some adjustments to the formatting need to be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fund_matrix_list_all = [list((y_pred.iloc[1])[0:9]) for i in range(y_pred.shape[0])]\n",
    "fund_matrix_list_all = [\" \".join([str(num) for num in fundmatrix]) for fundmatrix in fund_matrix_list_all]\n",
    "sample_id_list_all = [\";\".join([\"phototourism\",scene,pair]) for scene, pair in zip(x_test_short.iloc[:,3],x_test_short.iloc[:,2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation metrics are used, as demonstrated in https://www.kaggle.com/code/tmyok1984/imc2022-validation-code/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAA=0.00536 (n=1250)\n"
     ]
    }
   ],
   "source": [
    "maa = validation.evaluate(input_dir, sample_id_list_all, fund_matrix_list_all)\n",
    "print(f'mAA={maa:.05f} (n={len(sample_id_list_all)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as is apparent, the accuracy is abysmal.\n",
    "The main reasons for this are probably:\n",
    "- the small sample size, as explained above. Only using a small fraction of the actual data does not deliver an appropriate model, probably introducing bias.\n",
    "- the model is too simple: although the predictor consists of 9 different SVMs, each fitting for every single pixel color channel, this is far from sophisticated enough to grasp the relative movement of objects within the images. This introduces even more bias.\n",
    "- The data format here is extremely limiting to the applicability and clearly not appropriate for the dimensionality of the images. Actually using all provided data might take several days to compute, with a very limited chance of success. A proper dimensionality reduction is necessary for handling the image datasets.\n",
    "- The data need sanitising first. I.e. images with a covisibility below 0.1 are not recommended for training, as stated by the competition hosts. Such image pairs are having insufficient overlap (or none at all). this weakens the model's predictive power even further. Additionally, small thumbnail images provide too little feature information to classify them properly.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "789a077e75d230d6817791d042a8240da14a0b665837b21bc2c38ddd887efce6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
