{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing as prep\n",
    "import validation\n",
    "import plotting\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "\n",
    "input_dir = '../../data/train/' # directory of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for use with AMD GPUs\n",
    "# pip3 install torch --extra-index-url https://download.pytorch.org/whl/rocm5.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoFTR config\n",
    "default_cfg = {\n",
    "    'backbone_type': 'ResNetFPN',\n",
    "    'resolution': (8, 2),\n",
    "    'fine_window_size': 5,\n",
    "    'fine_concat_coarse_feat': True,\n",
    "    'resnetfpn': {'initial_dim': 128, 'block_dims': [128, 196, 256]},\n",
    "    'coarse': {\n",
    "        'd_model': 256,\n",
    "        'd_ffn': 256,\n",
    "        'nhead': 8,\n",
    "        'layer_names': ['self', 'cross', 'self', 'cross', 'self', 'cross', 'self', 'cross'],\n",
    "        'attention': 'linear',\n",
    "        'temp_bug_fix': False,\n",
    "    },\n",
    "    'match_coarse': {\n",
    "        'thr': 0.2,\n",
    "        'border_rm': 2,\n",
    "        'match_type': 'dual_softmax',\n",
    "        'dsmax_temperature': 0.1,\n",
    "        'skh_iters': 3,\n",
    "        'skh_init_bin_score': 1.0,\n",
    "        'skh_prefilter': True,\n",
    "        'train_coarse_percent': 0.4,\n",
    "        'train_pad_num_gt_min': 200,\n",
    "    },\n",
    "    'fine': {'d_model': 128, 'd_ffn': 128, 'nhead': 8, 'layer_names': ['self', 'cross'], 'attention': 'linear'},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brandenburg_gate',\n",
       " 'british_museum',\n",
       " 'buckingham_palace',\n",
       " 'colosseum_exterior',\n",
       " 'grand_place_brussels',\n",
       " 'lincoln_memorial_statue',\n",
       " 'notre_dame_front_facade',\n",
       " 'pantheon_exterior',\n",
       " 'piazza_san_marco',\n",
       " 'sacre_coeur',\n",
       " 'sagrada_familia',\n",
       " 'st_pauls_cathedral',\n",
       " 'st_peters_square',\n",
       " 'taj_mahal',\n",
       " 'temple_nara_japan',\n",
       " 'trevi_fountain']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scenes = prep.get_scenes(input_dir)\n",
    "all_scenes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = [all_scenes[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading category 1 of 1: brandenburg_gate\n"
     ]
    }
   ],
   "source": [
    "pairs = prep.load_pairs(scenes,input_dir)\n",
    "pairs = pairs.query('covisibility > 0.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>covisibility</th>\n",
       "      <th>fundamental_matrix</th>\n",
       "      <th>scene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90920828_5082887495-20133057_3035445116</td>\n",
       "      <td>0.905</td>\n",
       "      <td>-9.27158516e-04 1.22034601e-01 -9.87725452e+01...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90920828_5082887495-17262282_1141017004</td>\n",
       "      <td>0.936</td>\n",
       "      <td>1.68899800e-03 1.18269247e-01 -1.02939518e+02 ...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20133057_3035445116-17262282_1141017004</td>\n",
       "      <td>0.908</td>\n",
       "      <td>-5.56308440e-04 1.74170978e-02 -2.49391042e+01...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38600512_2168650655-17262282_1141017004</td>\n",
       "      <td>0.901</td>\n",
       "      <td>1.26837683e-02 -5.42924979e-01 4.29820975e+02 ...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60770994_853214983-17262282_1141017004</td>\n",
       "      <td>0.912</td>\n",
       "      <td>-1.05214974e-02 -4.87393290e-01 3.90468870e+02...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>60824110_1469539304-08468928_1469537330</td>\n",
       "      <td>0.811</td>\n",
       "      <td>8.91990074e-03 -2.94788540e-01 1.50446598e+02 ...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>66720928_3418295149-20133057_3035445116</td>\n",
       "      <td>0.809</td>\n",
       "      <td>-1.22423910e-03 5.86196722e-01 -4.42487049e+02...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>66720928_3418295149-02936509_94852264</td>\n",
       "      <td>0.811</td>\n",
       "      <td>3.41079145e-02 3.74560749e+00 -2.52775986e+03 ...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>66720928_3418295149-08814095_3507579332</td>\n",
       "      <td>0.802</td>\n",
       "      <td>1.56312064e-01 4.13537791e-01 -6.69635804e+02 ...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>67266149_8114963267-20133057_3035445116</td>\n",
       "      <td>0.845</td>\n",
       "      <td>1.18994488e-02 5.40218145e+00 -3.52321362e+03 ...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        pair  covisibility  \\\n",
       "0    90920828_5082887495-20133057_3035445116         0.905   \n",
       "1    90920828_5082887495-17262282_1141017004         0.936   \n",
       "2    20133057_3035445116-17262282_1141017004         0.908   \n",
       "3    38600512_2168650655-17262282_1141017004         0.901   \n",
       "4     60770994_853214983-17262282_1141017004         0.912   \n",
       "..                                       ...           ...   \n",
       "127  60824110_1469539304-08468928_1469537330         0.811   \n",
       "129  66720928_3418295149-20133057_3035445116         0.809   \n",
       "130    66720928_3418295149-02936509_94852264         0.811   \n",
       "131  66720928_3418295149-08814095_3507579332         0.802   \n",
       "132  67266149_8114963267-20133057_3035445116         0.845   \n",
       "\n",
       "                                    fundamental_matrix             scene  \n",
       "0    -9.27158516e-04 1.22034601e-01 -9.87725452e+01...  brandenburg_gate  \n",
       "1    1.68899800e-03 1.18269247e-01 -1.02939518e+02 ...  brandenburg_gate  \n",
       "2    -5.56308440e-04 1.74170978e-02 -2.49391042e+01...  brandenburg_gate  \n",
       "3    1.26837683e-02 -5.42924979e-01 4.29820975e+02 ...  brandenburg_gate  \n",
       "4    -1.05214974e-02 -4.87393290e-01 3.90468870e+02...  brandenburg_gate  \n",
       "..                                                 ...               ...  \n",
       "127  8.91990074e-03 -2.94788540e-01 1.50446598e+02 ...  brandenburg_gate  \n",
       "129  -1.22423910e-03 5.86196722e-01 -4.42487049e+02...  brandenburg_gate  \n",
       "130  3.41079145e-02 3.74560749e+00 -2.52775986e+03 ...  brandenburg_gate  \n",
       "131  1.56312064e-01 4.13537791e-01 -6.69635804e+02 ...  brandenburg_gate  \n",
       "132  1.18994488e-02 5.40218145e+00 -3.52321362e+03 ...  brandenburg_gate  \n",
       "\n",
       "[129 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LoFTR\n",
    "matcher = KF.LoFTR(config=default_cfg)\n",
    "matcher.load_state_dict(torch.load(\"weights/outdoor_ds.ckpt\")['state_dict'])\n",
    "matcher = matcher.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dieter/Documents/Python/capstone-project-image-matching-challenge/.venv/lib/python3.9/site-packages/kornia/feature/loftr/utils/coarse_matching.py:243: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  mkpts0_c = torch.stack([i_ids % data['hw0_c'][1], i_ids // data['hw0_c'][1]], dim=1) * scale0\n",
      "/home/dieter/Documents/Python/capstone-project-image-matching-challenge/.venv/lib/python3.9/site-packages/kornia/feature/loftr/utils/coarse_matching.py:244: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  mkpts1_c = torch.stack([j_ids % data['hw1_c'][1], j_ids // data['hw1_c'][1]], dim=1) * scale1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAA=0.20000 (n=10)\n"
     ]
    }
   ],
   "source": [
    "fund_matrix_list = []\n",
    "pair_id_list = []\n",
    "\n",
    "for index, row in pairs.head(10).iterrows():\n",
    "    \n",
    "    split_pair = pairs.pair[index].split('-')\n",
    "    img_id0 = split_pair[0]\n",
    "    img_id1 = split_pair[1]\n",
    "    \n",
    "    img0_pth = os.path.join(input_dir, pairs.scene[index], \"images\", str(img_id0 + '.jpg'))\n",
    "    img1_pth = os.path.join(input_dir, pairs.scene[index], \"images\", str(img_id1 + '.jpg'))\n",
    "    img0 = prep.load_torch_image(img0_pth, device)\n",
    "    img1 = prep.load_torch_image(img1_pth, device)\n",
    "    batch = {\"image0\": K.color.rgb_to_grayscale(img0), \n",
    "            \"image1\": K.color.rgb_to_grayscale(img1)}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        matcher(batch)\n",
    "        mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "        mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "        mconf = batch['mconf'].cpu().numpy()\n",
    "        \n",
    "    F = cv2.findFundamentalMat(mkpts0, mkpts1, cv2.USAC_MAGSAC, 0.2, 0.99999, 50000)\n",
    "    \n",
    "    fund_matrix_list.append(\" \".join(str(num) for num in F[0].flatten().tolist()))\n",
    "    pair_id_list.append(\";\".join([\"phototourism\",pairs.scene[index],pairs.pair[index]]))\n",
    "    \n",
    "maa = validation.evaluate(input_dir, pair_id_list, fund_matrix_list)\n",
    "print(f'mAA={maa:.05f} (n={len(pair_id_list)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo: \n",
    "- decompose F and plot\n",
    "- save mkpts and mconf, so it can be used for drawing etc. later\n",
    "- DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoFTR example on single image pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LoFTR and load two images\n",
    "# matcher.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.\n",
    "matcher = KF.LoFTR(config=default_cfg)\n",
    "matcher.load_state_dict(torch.load(\"weights/outdoor_ds.ckpt\")['state_dict'])\n",
    "matcher = matcher.to(\"cpu\").eval()\n",
    "\n",
    "img0_pth = \"../../data/test_images/1cf87530/0143f47ee9e54243a1b8454f3e91621a.png\"\n",
    "img1_pth = \"../../data/test_images/1cf87530/a5a9975574c94ff9a285f58c39b53d2c.png\"\n",
    "img0_raw = cv2.imread(img0_pth, cv2.IMREAD_GRAYSCALE)\n",
    "img1_raw = cv2.imread(img1_pth, cv2.IMREAD_GRAYSCALE)\n",
    "img0_raw = cv2.resize(img0_raw, (640, 480))\n",
    "img1_raw = cv2.resize(img1_raw, (640, 480))\n",
    "\n",
    "img0 = torch.from_numpy(img0_raw)[None][None] / 255.\n",
    "img1 = torch.from_numpy(img1_raw)[None][None] / 255.\n",
    "batch = {'image0': img0, 'image1': img1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference with LoFTR and get prediction\n",
    "# torch.no_grad() impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you wonâ€™t be able to backprop (which you donâ€™t want in an eval script).\n",
    "with torch.no_grad():\n",
    "    matcher(batch)\n",
    "    mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "    mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "    mconf = batch['mconf'].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw\n",
    "color = cm.jet(mconf)\n",
    "text = [\n",
    "    'LoFTR',\n",
    "    'Matches: {}'.format(len(mkpts0)),\n",
    "]\n",
    "fig = plotting.make_matching_figure(img0_raw, img1_raw, mkpts0, mkpts1, color, text=text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3cb6f8f94b137662f019060dc8dbcf462a31c1fc7c9d402b8b05f4adcd49394c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
