{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils.plotting import make_matching_figure\n",
    "from src.loftr import LoFTR, default_cfg\n",
    "import preprocessing as prep\n",
    "import validation\n",
    "\n",
    "input_dir = '../../data/train/' # directory of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brandenburg_gate',\n",
       " 'british_museum',\n",
       " 'buckingham_palace',\n",
       " 'colosseum_exterior',\n",
       " 'grand_place_brussels',\n",
       " 'lincoln_memorial_statue',\n",
       " 'notre_dame_front_facade',\n",
       " 'pantheon_exterior',\n",
       " 'piazza_san_marco',\n",
       " 'sacre_coeur',\n",
       " 'sagrada_familia',\n",
       " 'st_pauls_cathedral',\n",
       " 'st_peters_square',\n",
       " 'taj_mahal',\n",
       " 'temple_nara_japan',\n",
       " 'trevi_fountain']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scenes = prep.get_scenes(input_dir)\n",
    "all_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = [all_scenes[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading category 1 of 1: brandenburg_gate\n"
     ]
    }
   ],
   "source": [
    "pairs = prep.load_pairs(scenes,input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>covisibility</th>\n",
       "      <th>fundamental_matrix</th>\n",
       "      <th>scene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90920828_5082887495-20133057_3035445116</td>\n",
       "      <td>0.905</td>\n",
       "      <td>-9.27158516e-04 1.22034601e-01 -9.87725452e+01...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90920828_5082887495-17262282_1141017004</td>\n",
       "      <td>0.936</td>\n",
       "      <td>1.68899800e-03 1.18269247e-01 -1.02939518e+02 ...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20133057_3035445116-17262282_1141017004</td>\n",
       "      <td>0.908</td>\n",
       "      <td>-5.56308440e-04 1.74170978e-02 -2.49391042e+01...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38600512_2168650655-17262282_1141017004</td>\n",
       "      <td>0.901</td>\n",
       "      <td>1.26837683e-02 -5.42924979e-01 4.29820975e+02 ...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60770994_853214983-17262282_1141017004</td>\n",
       "      <td>0.912</td>\n",
       "      <td>-1.05214974e-02 -4.87393290e-01 3.90468870e+02...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61070</th>\n",
       "      <td>67494650_6905234882-63229395_2704362565</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-1.83952792e-02 1.11447290e-01 -8.55666688e+01...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61071</th>\n",
       "      <td>67494650_6905234882-65128211_1900926684</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-3.19883341e-02 5.26823598e-01 -3.14236536e+02...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61072</th>\n",
       "      <td>67494650_6905234882-65235481_5082884383</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-1.39080165e-02 7.79098666e-01 -4.67854880e+02...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61073</th>\n",
       "      <td>67494650_6905234882-67080033_7235561554</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.69361910e-02 -1.65968509e+00 9.28898161e+02 ...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61074</th>\n",
       "      <td>67494650_6905234882-67121330_501219352</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-9.63434154e-04 9.39125652e-01 -5.53077819e+02...</td>\n",
       "      <td>brandenburg_gate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61075 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          pair  covisibility  \\\n",
       "0      90920828_5082887495-20133057_3035445116         0.905   \n",
       "1      90920828_5082887495-17262282_1141017004         0.936   \n",
       "2      20133057_3035445116-17262282_1141017004         0.908   \n",
       "3      38600512_2168650655-17262282_1141017004         0.901   \n",
       "4       60770994_853214983-17262282_1141017004         0.912   \n",
       "...                                        ...           ...   \n",
       "61070  67494650_6905234882-63229395_2704362565         0.019   \n",
       "61071  67494650_6905234882-65128211_1900926684         0.037   \n",
       "61072  67494650_6905234882-65235481_5082884383         0.095   \n",
       "61073  67494650_6905234882-67080033_7235561554         0.000   \n",
       "61074   67494650_6905234882-67121330_501219352         0.075   \n",
       "\n",
       "                                      fundamental_matrix             scene  \n",
       "0      -9.27158516e-04 1.22034601e-01 -9.87725452e+01...  brandenburg_gate  \n",
       "1      1.68899800e-03 1.18269247e-01 -1.02939518e+02 ...  brandenburg_gate  \n",
       "2      -5.56308440e-04 1.74170978e-02 -2.49391042e+01...  brandenburg_gate  \n",
       "3      1.26837683e-02 -5.42924979e-01 4.29820975e+02 ...  brandenburg_gate  \n",
       "4      -1.05214974e-02 -4.87393290e-01 3.90468870e+02...  brandenburg_gate  \n",
       "...                                                  ...               ...  \n",
       "61070  -1.83952792e-02 1.11447290e-01 -8.55666688e+01...  brandenburg_gate  \n",
       "61071  -3.19883341e-02 5.26823598e-01 -3.14236536e+02...  brandenburg_gate  \n",
       "61072  -1.39080165e-02 7.79098666e-01 -4.67854880e+02...  brandenburg_gate  \n",
       "61073  9.69361910e-02 -1.65968509e+00 9.28898161e+02 ...  brandenburg_gate  \n",
       "61074  -9.63434154e-04 9.39125652e-01 -5.53077819e+02...  brandenburg_gate  \n",
       "\n",
       "[61075 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LoFTR\n",
    "matcher = LoFTR(config=default_cfg)\n",
    "matcher.load_state_dict(torch.load(\"weights/outdoor_ds.ckpt\")['state_dict'])\n",
    "matcher = matcher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAA=0.46000 (n=5)\n"
     ]
    }
   ],
   "source": [
    "fund_matrix_list = []\n",
    "pair_id_list = []\n",
    "\n",
    "for index, row in pairs.head(5).iterrows():\n",
    "    \n",
    "    split_pair = pairs.pair[index].split('-')\n",
    "    img_id0 = split_pair[0]\n",
    "    img_id1 = split_pair[1]\n",
    "    \n",
    "    img0_pth = os.path.join(input_dir, pairs.scene[index], \"images\", str(img_id0 + '.jpg'))\n",
    "    img1_pth = os.path.join(input_dir, pairs.scene[index], \"images\", str(img_id1 + '.jpg'))\n",
    "    img0_raw = cv2.imread(img0_pth, cv2.IMREAD_GRAYSCALE)\n",
    "    img1_raw = cv2.imread(img1_pth, cv2.IMREAD_GRAYSCALE)\n",
    "    img0_raw = cv2.resize(img0_raw, (640, 480))\n",
    "    img1_raw = cv2.resize(img1_raw, (640, 480))\n",
    "\n",
    "    img0 = torch.from_numpy(img0_raw)[None][None] / 255.\n",
    "    img1 = torch.from_numpy(img1_raw)[None][None] / 255.\n",
    "    batch = {'image0': img0, 'image1': img1}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        matcher(batch)\n",
    "        mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "        mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "        mconf = batch['mconf'].cpu().numpy()\n",
    "        \n",
    "    F = cv2.findFundamentalMat(mkpts0, mkpts1, cv2.USAC_MAGSAC, 0.1, 0.99, 20000)\n",
    "    \n",
    "    fund_matrix_list.append(\" \".join(str(num) for num in F[0].flatten().tolist()))\n",
    "    pair_id_list.append(\";\".join([\"phototourism\",pairs.scene[index],pairs.pair[index]]))\n",
    "    \n",
    "maa = validation.evaluate(input_dir, pair_id_list, fund_matrix_list)\n",
    "print(f'mAA={maa:.05f} (n={len(pair_id_list)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo: \n",
    "- add IF CPU/GPU\n",
    "- save mkpts and mconf, so it can be used for drawing later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw\n",
    "color = cm.jet(mconf)\n",
    "text = [\n",
    "    'LoFTR',\n",
    "    'Matches: {}'.format(len(mkpts0)),\n",
    "]\n",
    "fig = make_matching_figure(img0_raw, img1_raw, mkpts0, mkpts1, color, text=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoFTR example on single image pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LoFTR and load two images\n",
    "# matcher.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.\n",
    "matcher = LoFTR(config=default_cfg)\n",
    "matcher.load_state_dict(torch.load(\"weights/outdoor_ds.ckpt\")['state_dict'])\n",
    "matcher = matcher.eval()\n",
    "\n",
    "img0_pth = \"../../data/test_images/1cf87530/0143f47ee9e54243a1b8454f3e91621a.png\"\n",
    "img1_pth = \"../../data/test_images/1cf87530/a5a9975574c94ff9a285f58c39b53d2c.png\"\n",
    "img0_raw = cv2.imread(img0_pth, cv2.IMREAD_GRAYSCALE)\n",
    "img1_raw = cv2.imread(img1_pth, cv2.IMREAD_GRAYSCALE)\n",
    "img0_raw = cv2.resize(img0_raw, (640, 480))\n",
    "img1_raw = cv2.resize(img1_raw, (640, 480))\n",
    "\n",
    "img0 = torch.from_numpy(img0_raw)[None][None] / 255.\n",
    "img1 = torch.from_numpy(img1_raw)[None][None] / 255.\n",
    "batch = {'image0': img0, 'image1': img1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference with LoFTR and get prediction\n",
    "# torch.no_grad() impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop (which you don’t want in an eval script).\n",
    "with torch.no_grad():\n",
    "    matcher(batch)\n",
    "    mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "    mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "    mconf = batch['mconf'].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw\n",
    "color = cm.jet(mconf)\n",
    "text = [\n",
    "    'LoFTR',\n",
    "    'Matches: {}'.format(len(mkpts0)),\n",
    "]\n",
    "fig = make_matching_figure(img0_raw, img1_raw, mkpts0, mkpts1, color, text=text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da0107cc955c643a970c078967c47321515469ab36be1559d5e88ff85a30550a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
