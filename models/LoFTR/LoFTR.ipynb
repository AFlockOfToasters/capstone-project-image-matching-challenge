{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "import preprocessing\n",
    "import validation\n",
    "import plotting\n",
    "import tqdm\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "input_dir = '../../data/train/' # directory of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE LATER\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for use with MacBooks\n",
    "# pip install torch\n",
    "\n",
    "# for use with AMD GPUs on Linux\n",
    "# pip3 install torch --extra-index-url https://download.pytorch.org/whl/rocm5.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all scene names from the training data\n",
    "all_scenes = preprocessing.get_scenes(input_dir)\n",
    "all_scenes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all image pairs, along with their covisibility and fundamental matrix\n",
    "\n",
    "#scenes = all_scenes # load all scenes\n",
    "scenes = [all_scenes[0]] # load only the first scene\n",
    "\n",
    "pairs = preprocessing.load_pairs(scenes,input_dir)\n",
    "\n",
    "# Load either all pairs, or only withing a specific covisibility range\n",
    "pairs = pairs.reset_index()\n",
    "#pairs = pairs.query('covisibility > 0.95').reset_index()\n",
    "#pairs = pairs.query('0.7 < covisibility < 0.8').reset_index()\n",
    "\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if a GPU is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LoFTR and load the outdoor weights\n",
    "matcher = KF.LoFTR(pretrained='outdoor')\n",
    "matcher = matcher.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LoFTR on the image pairs loaded previously. The output is a DataFrame containing all relevant data for each image pair analyzed.\n",
    "scene_list = []\n",
    "fund_matrix_list = []\n",
    "pair_list = []\n",
    "fund_matrix_eval = []\n",
    "pair_eval = []\n",
    "mkpts0_list = []\n",
    "mkpts1_list = []\n",
    "mconf_list = []\n",
    "\n",
    "for index, row in pairs.head(3).iterrows(): # Head controls how many image pairs are analyzed\n",
    "    \n",
    "    split_pair = pairs.pair[index].split('-')\n",
    "    img_id0 = split_pair[0]\n",
    "    img_id1 = split_pair[1]\n",
    "    \n",
    "    img0_pth = os.path.join(input_dir, pairs.scene[index], \"images\", str(img_id0 + '.jpg'))\n",
    "    img1_pth = os.path.join(input_dir, pairs.scene[index], \"images\", str(img_id1 + '.jpg'))\n",
    "    img0 = preprocessing.load_torch_image(img0_pth, device)\n",
    "    img1 = preprocessing.load_torch_image(img1_pth, device)\n",
    "    batch = {\"image0\": K.color.rgb_to_grayscale(img0), \n",
    "            \"image1\": K.color.rgb_to_grayscale(img1)}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        matcher(batch)\n",
    "        mkpts0 = batch['mkpts0_f'].cpu().numpy()\n",
    "        mkpts1 = batch['mkpts1_f'].cpu().numpy()\n",
    "        mconf = batch['mconf'].cpu().numpy()\n",
    "        \n",
    "    F = cv2.findFundamentalMat(mkpts0, mkpts1, cv2.USAC_MAGSAC, 0.2, 0.99999, 50000)\n",
    "    \n",
    "    scene_list.append(pairs.scene[index])\n",
    "    fund_matrix_list.append(F[0])\n",
    "    pair_list.append(pairs.pair[index])\n",
    "    fund_matrix_eval.append(\" \".join(str(num) for num in F[0].flatten().tolist()))\n",
    "    pair_eval.append(\";\".join([\"phototourism\",pairs.scene[index],pairs.pair[index]]))\n",
    "    mkpts0_list.append(mkpts0)\n",
    "    mkpts1_list.append(mkpts1)\n",
    "    mconf_list.append(mconf)\n",
    "    \n",
    "results = pd.DataFrame({'scene': scene_list, 'pair': pair_list, 'fund_matrix': fund_matrix_list, \n",
    "                        'mkpts0': mkpts0_list, 'mkpts1': mkpts1_list, 'mconf': mconf_list,\n",
    "                        'pair_eval': pair_eval, 'fund_matrix_eval': fund_matrix_eval}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the validation on all results and return the mean average accuracy\n",
    "maa = validation.evaluate(input_dir, results.pair_eval, results.fund_matrix_eval)\n",
    "print(f'mAA={maa} (n={len(results)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw matches for a single pair from the results\n",
    "\n",
    "index = 7 # select image pair from results DataFrame\n",
    "threshold = 0 # setting a confidence threshold (0 == no threshold)\n",
    "\n",
    "df_draw = pd.DataFrame({'mkpts0': results.mkpts0[index].tolist(), 'mkpts1': results.mkpts1[index].tolist(), 'mconf': results.mconf[index].tolist()})\n",
    "\n",
    "img0_pth = os.path.join(input_dir, results.scene[index], \"images\", str(results.pair[index].split('-')[0] + '.jpg'))\n",
    "img1_pth = os.path.join(input_dir, results.scene[index], \"images\", str(results.pair[index].split('-')[1] + '.jpg'))\n",
    "img0 = load_image(img0_pth)\n",
    "img1 = load_image(img1_pth)\n",
    "\n",
    "color = cm.jet(df_draw.query(f'mconf > {threshold}').mconf)\n",
    "text = [\n",
    "    'LoFTR',\n",
    "    'Matches: {}'.format(len(df_draw.query(f'mconf > {threshold}')))]\n",
    "fig = plotting.make_matching_figure(img0, img1, np.array(df_draw.query(f'mconf > {threshold}').mkpts0.values.tolist()), \n",
    "                                    np.array(df_draw.query(f'mconf > {threshold}').mkpts1.values.tolist()), color, text=text, dpi=150, alpha = 0.1, lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw matches for a single pair from the results\n",
    "\n",
    "index = 7 # select image pair from results DataFrame\n",
    "threshold = 0 # setting a confidence threshold (0 == no threshold)\n",
    "\n",
    "df_draw = pd.DataFrame({'mkpts0': results.mkpts0[index].tolist(), 'mkpts1': results.mkpts1[index].tolist(), 'mconf': results.mconf[index].tolist()})\n",
    "\n",
    "img0_pth = os.path.join(input_dir, results.scene[index], \"images\", str(results.pair[index].split('-')[0] + '.jpg'))\n",
    "img1_pth = os.path.join(input_dir, results.scene[index], \"images\", str(results.pair[index].split('-')[1] + '.jpg'))\n",
    "img0 = load_image(img0_pth)\n",
    "img1 = load_image(img1_pth)\n",
    "\n",
    "color = cm.jet(df_draw.query(f'mconf > {threshold}').mconf)\n",
    "color_trans = color * np.full(color.shape,255)\n",
    "color_trans = np.delete(color_trans, -1, axis=1)\n",
    "color_plotly = [f'rgb({\",\".join(c)})' for c in color_trans.astype(str)]\n",
    "text = [\n",
    "    'LoFTR',\n",
    "    'Matches: {}'.format(len(df_draw.query(f'mconf > {threshold}')))]\n",
    "fig = plotting.make_matching_figure_plotly(img0, img1, np.array(df_draw.query(f'mconf > {threshold}').mkpts0.values.tolist()), \n",
    "                                    np.array(df_draw.query(f'mconf > {threshold}').mkpts1.values.tolist()), color_plotly, text=text, alpha = 0.1)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = cv2.findFundamentalMat(np.array(df_draw.query(f'mconf > {threshold}').mkpts0.values.tolist()), np.array(df_draw.query(f'mconf > {threshold}').mkpts1.values.tolist()), cv2.USAC_MAGSAC, 0.2, 0.99999, 50000)\n",
    "single_evaluate_scene = results.scene[index]\n",
    "single_evaluate_pair = results.pair[index]\n",
    "single_evaluate_pair_eval = results.pair_eval[index]\n",
    "aa = validation.evaluate_single(input_dir, single_evaluate_pair_eval, \" \".join(str(num) for num in F[0].flatten().tolist()))\n",
    "print(f'Accuracy = {aa[0]}\\nAngle error (degrees) = {aa[1][single_evaluate_scene][single_evaluate_pair]}\\nDistance error (meters) = {aa[2][single_evaluate_scene][single_evaluate_pair]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "X = results.mkpts0[7]\n",
    "Y = results.mkpts1[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y[:, 0], Y[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = DBSCAN(eps=20, min_samples=5).fit(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c = clustering.labels_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da0107cc955c643a970c078967c47321515469ab36be1559d5e88ff85a30550a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
